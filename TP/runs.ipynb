{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45956ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9aa37b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DUR_RE = re.compile(r\"(?P<val>[\\d.]+)\\s*(?P<unit>ns|µs|us|ms|s|m|h)\")\n",
    "_UNIT_TO_MS = {\"ns\": 1e-6, \"µs\": 1e-3, \"us\": 1e-3, \"ms\": 1, \"s\": 1000, \"m\": 60000, \"h\": 3600000}\n",
    "\n",
    "def duration_to_ms(text: str) -> float:\n",
    "    total_ms = 0.0\n",
    "    for m in _DUR_RE.finditer(text):\n",
    "        total_ms += float(m.group(\"val\")) * _UNIT_TO_MS[m.group(\"unit\")]\n",
    "    return total_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd04ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_RE = re.compile(r\"(?P<user1>\\d+)\\s*-\\s*(?P<user2>\\d+)\\s*:\\s*(?P<val>[-\\d.]+)\")\n",
    "CON_RE = re.compile(r\"(?P<user1>\\d+)\\s*-\\s*(?P<user2>\\d+)\\s*:\\s*(?P<val>[-\\d.]+)\")\n",
    "TIME_RE = re.compile(r\"(?:Sequential|Concurrent)\\s+similarities\\s+computed\\s+in\\s+(?P<duration>.+?)(?:\\s+\\(workers=\\d+\\))?,\\s+pairs=\\d+\", re.I)\n",
    "\n",
    "def run_algo(go_file: Path, alg: str, \n",
    "            sample_users: int = 0, sample_items: int = 0):\n",
    "    cmd = [\n",
    "        \"go\", \"run\", str(go_file),\n",
    "        f\"--algorithm={alg}\",\n",
    "        f\"--sample_users={sample_users}\",\n",
    "        f\"--sample_items={sample_items}\",\n",
    "    ]\n",
    "    res = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "    stdout = res.stdout.splitlines()\n",
    "\n",
    "    seq_pairs, con_pairs = [], []\n",
    "    seq_time, con_time = None, None\n",
    "    in_seq_pairs = in_con_pairs = False\n",
    "\n",
    "    for line in stdout:\n",
    "        if \"Top-10 similar user pairs (seq):\" in line:\n",
    "            in_seq_pairs = True\n",
    "            in_con_pairs = False\n",
    "            continue\n",
    "        elif \"Top-10 similar user pairs (con):\" in line:\n",
    "            in_seq_pairs = False\n",
    "            in_con_pairs = True\n",
    "            continue\n",
    "        elif \"Time\" not in line and (in_seq_pairs or in_con_pairs):\n",
    "            if m := SEQ_RE.search(line):\n",
    "                pairs = seq_pairs if in_seq_pairs else con_pairs\n",
    "                pairs.append({\n",
    "                    \"user1\": int(m.group(\"user1\")),\n",
    "                    \"user2\": int(m.group(\"user2\")),\n",
    "                    \"value\": float(m.group(\"val\"))\n",
    "                })\n",
    "        elif (m := TIME_RE.search(line)):\n",
    "            ms = duration_to_ms(m.group(\"duration\"))\n",
    "            if \"Sequential\" in line:\n",
    "                seq_time = ms\n",
    "            else:\n",
    "                con_time = ms\n",
    "\n",
    "    records = []\n",
    "    if seq_time is not None and seq_pairs:\n",
    "        records.append({\n",
    "            \"algorithm\": alg,\n",
    "            \"mode\": \"sequential\",\n",
    "            \"value\": np.mean([p[\"value\"] for p in seq_pairs]),\n",
    "            \"duration_ms\": seq_time,\n",
    "            \"top_pairs\": seq_pairs\n",
    "        })\n",
    "    if con_time is not None and con_pairs:\n",
    "        records.append({\n",
    "            \"algorithm\": alg,\n",
    "            \"mode\": \"concurrent\",\n",
    "            \"value\": np.mean([p[\"value\"] for p in con_pairs]),\n",
    "            \"duration_ms\": con_time,\n",
    "            \"top_pairs\": con_pairs\n",
    "        })\n",
    "\n",
    "    return records, \"\\n\".join(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0080bfa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "benchmark() missing 1 required positional argument: 'goroutines_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(records)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m df = \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgo_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtp.go\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43malgs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpearson\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Note: jaccard not supported in tp.go\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_users\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Limit to 1000 users as in the example output\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepeats\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reduced repeats since we're reading from CSV\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: benchmark() missing 1 required positional argument: 'goroutines_list'"
     ]
    }
   ],
   "source": [
    "def benchmark(go_file, algs, goroutines_list, \n",
    "            sample_users=1000, sample_items=0, repeats=20):\n",
    "    records = []\n",
    "\n",
    "    for goroutines in goroutines_list:\n",
    "        for alg in algs:\n",
    "            for r in range(repeats):\n",
    "                recs, _ = run_algo(\n",
    "                    go_file=go_file,\n",
    "                    alg=alg,\n",
    "                    sample_users=sample_users,\n",
    "                    sample_items=sample_items\n",
    "                )\n",
    "                for rec in recs:\n",
    "                    rec[\"run\"] = r\n",
    "                    records.append(rec)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Example usage:\n",
    "df = benchmark(\n",
    "    go_file=Path(\"tp.go\"),\n",
    "    algs=[\"cosine\", \"pearson\"],  # Note: jaccard not supported in tp.go\n",
    "    sample_users=1000,  # Limit to 1000 users as in the example output\n",
    "    repeats=5  # Reduced repeats since we're reading from CSV\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7a13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby([\"algorithm\", \"mode\", \"dim\", \"goroutines\"]).agg(\n",
    "    mean_time=(\"duration_ms\", \"mean\"),\n",
    "    std_time=(\"duration_ms\", \"std\"),\n",
    "    mean_value=(\"value\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d08ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=df,\n",
    "    kind=\"line\",\n",
    "    x=\"goroutines\", y=\"duration_ms\",\n",
    "    hue=\"mode\", style=\"dim\",\n",
    "    col=\"algorithm\", col_wrap=3,\n",
    "    markers=True, dashes=False,\n",
    "    errorbar=(\"sd\")  # show variability from your repeats\n",
    ")\n",
    "g.set_axis_labels(\"Goroutines\", \"Duration (ms)\")\n",
    "g.fig.suptitle(\"Runtime vs Goroutines (mean ± sd per condition)\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7913dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build per-run pivot to pair seq/con, then average to be robust\n",
    "per_run = df.pivot_table(\n",
    "    index=[\"algorithm\",\"dim\",\"goroutines\",\"run\"],\n",
    "    columns=\"mode\",\n",
    "    values=\"duration_ms\",\n",
    "    aggfunc=\"first\"\n",
    ").reset_index()\n",
    "\n",
    "# Compute ratios per run\n",
    "per_run[\"ratio_con_over_seq\"] = per_run[\"concurrent\"] / per_run[\"sequential\"]\n",
    "per_run[\"pct_con_of_seq\"]     = 100 * per_run[\"ratio_con_over_seq\"]\n",
    "per_run[\"pct_improve\"]        = 100 * (1 - per_run[\"ratio_con_over_seq\"])\n",
    "\n",
    "# Average across repeats for plotting\n",
    "pct_summary = per_run.groupby([\"algorithm\",\"dim\",\"goroutines\"], as_index=False).agg(\n",
    "    mean_pct_con_of_seq=(\"pct_con_of_seq\",\"mean\"),\n",
    "    sd_pct_con_of_seq=(\"pct_con_of_seq\",\"std\"),\n",
    "    mean_pct_improve=(\"pct_improve\",\"mean\"),\n",
    "    sd_pct_improve=(\"pct_improve\",\"std\"),\n",
    ")\n",
    "\n",
    "# A) Concurrent as % of sequential (target < 100%)\n",
    "g1 = sns.relplot(\n",
    "    data=pct_summary, kind=\"line\",\n",
    "    x=\"goroutines\", y=\"mean_pct_con_of_seq\",\n",
    "    hue=\"dim\", col=\"algorithm\", col_wrap=3,\n",
    "    markers=True, dashes=False,\n",
    "    errorbar=None\n",
    ")\n",
    "for ax, (alg) in zip(g1.axes.flatten(), pct_summary[\"algorithm\"].unique()):\n",
    "    ax.axhline(100, ls=\"--\", lw=1, color=\"gray\")  # baseline: equal speed\n",
    "g1.set_axis_labels(\"Goroutines\", \"Concurrent as % of Sequential (↓ better)\")\n",
    "g1.fig.suptitle(\"Concurrent runtime relative to Sequential (mean across repeats)\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# B) % improvement (target > 0%)\n",
    "g2 = sns.relplot(\n",
    "    data=pct_summary, kind=\"line\",\n",
    "    x=\"goroutines\", y=\"mean_pct_improve\",\n",
    "    hue=\"dim\", col=\"algorithm\", col_wrap=3,\n",
    "    markers=True, dashes=False,\n",
    "    errorbar=None\n",
    ")\n",
    "for ax in g2.axes.flatten():\n",
    "    ax.axhline(0, ls=\"--\", lw=1, color=\"gray\")  # baseline: no improvement\n",
    "g2.set_axis_labels(\"Goroutines\", \"Improvement of Concurrent vs Sequential (%) (↑ better)\")\n",
    "g2.fig.suptitle(\"Percentage improvement from concurrency (mean across repeats)\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b21bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze top pairs distribution\n",
    "def analyze_top_pairs(df):\n",
    "    all_pairs = []\n",
    "    for _, row in df.iterrows():\n",
    "        pairs = pd.DataFrame(row[\"top_pairs\"])\n",
    "        pairs[\"algorithm\"] = row[\"algorithm\"]\n",
    "        pairs[\"mode\"] = row[\"mode\"]\n",
    "        pairs[\"run\"] = row[\"run\"]\n",
    "        pairs[\"goroutines\"] = row[\"goroutines\"]\n",
    "        all_pairs.append(pairs)\n",
    "    \n",
    "    pairs_df = pd.concat(all_pairs, ignore_index=True)\n",
    "    \n",
    "    # Calculate pair frequency\n",
    "    pair_counts = pairs_df.groupby([\"algorithm\", \"mode\", \"user1\", \"user2\"]).size().reset_index(name=\"frequency\")\n",
    "    pair_counts[\"pair\"] = pair_counts.apply(lambda x: f\"{x['user1']}-{x['user2']}\", axis=1)\n",
    "    \n",
    "    # Plot top 20 most frequent pairs\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for (alg, mode), group in pair_counts.groupby([\"algorithm\", \"mode\"]):\n",
    "        plt.subplot(1, 2, 1 if mode == \"sequential\" else 2)\n",
    "        top_pairs = group.nlargest(20, \"frequency\")\n",
    "        sns.barplot(data=top_pairs, x=\"frequency\", y=\"pair\")\n",
    "        plt.title(f\"{alg.title()} - {mode.title()}\")\n",
    "        plt.xlabel(\"Frequency in Top-10\")\n",
    "        plt.ylabel(\"User Pair\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_top_pairs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b2718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
